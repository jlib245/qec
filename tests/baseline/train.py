# tests/baseline/train.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import yaml
import argparse
import os

from qec_sim.data.dataset import OfflineQECDataset, OnlineQECDataset
from qec_sim.core.parameters import CodeParams, NoiseParams

# ìš°ë¦¬ê°€ ë§Œë“  ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜ ì„í¬íŠ¸
from qec_sim.models import build_model

def main(config_path):
    # 1. YAML ì„¤ì • ë¡œë“œ
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
        
    print(f"[{config_path}] ì„¤ì •ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    device = torch.device("cuda" if torch.cuda.is_available() else 
                          "mps" if torch.backends.mps.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

    # 2. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì„¤ì •
    train_config = config.get('training', {})
    batch_size = train_config.get('batch_size', 512)
    epochs = train_config.get('epochs', 20)
    lr = train_config.get('learning_rate', 0.001)
    data_mode = train_config.get('data_mode', 'offline')
    
    print(f"\në°ì´í„° ë¡œë“œ ëª¨ë“œ: {data_mode}")
    if data_mode == 'offline':
        train_path = train_config.get('train_path', 'datasets/d5_complex_noise/train.npz')
        val_path = train_config.get('val_path', 'datasets/d5_complex_noise/val.npz')
        train_dataset = OfflineQECDataset(train_path)
        val_dataset = OfflineQECDataset(val_path)
        
        # ë°ì´í„° í˜•íƒœ íŒŒì•…
        sample_x, sample_y = train_dataset[0]
        num_detectors = sample_x.shape[1]
        num_observables = sample_y.shape[0]
        
    elif data_mode == 'online':
        code_config = CodeParams(**config['code'])
        noise_config = NoiseParams(**config['noise'])
        
        # IterableDataset ìƒì„±
        train_dataset = OnlineQECDataset(code_config, noise_config, epoch_size=train_config.get('epoch_size', 100000))
        val_dataset = OnlineQECDataset(code_config, noise_config, epoch_size=train_config.get('val_size', 10000))
        
        # ì„ì‹œ íšŒë¡œë¥¼ ë§Œë“¤ì–´ ë””í…í„°/ì˜µì €ë²„ë¸” ìˆ˜ ì¶”ì¶œ
        from qec_sim.core.builder import CustomCircuitBuilder
        temp_circuit = CustomCircuitBuilder(code_config, noise_config).build()
        num_detectors = temp_circuit.num_detectors
        num_observables = temp_circuit.num_observables
    else:
        raise ValueError("data_modeëŠ” 'offline' ë˜ëŠ” 'online'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    # [ì£¼ì˜] OnlineDatasetì€ Iterableì´ë¯€ë¡œ shuffle=Falseë¡œ ë‘¬ì•¼ í•©ë‹ˆë‹¤.
    is_iterable = data_mode == 'online'
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=not is_iterable)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    print(f"ë””í…í„° ìˆ˜: {num_detectors}, ë…¼ë¦¬ íë¹„íŠ¸ ìˆ˜: {num_observables}")

    # 3. ëª¨ë¸ ë™ì  ìƒì„± (ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ìš©)
    model_config = config.get('model', {})
    model_name = model_config.get('name', 'erasure_mlp')
    model_kwargs = model_config.get('kwargs', {})
    
    # ì„¤ì • íŒŒì¼ì— ì íŒ ì´ë¦„ê³¼ ì¸ìë¡œ ëª¨ë¸ì„ ì¡°ë¦½í•©ë‹ˆë‹¤.
    model = build_model(model_name, num_detectors=num_detectors, num_observables=num_observables, **model_kwargs).to(device)
    
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    # 4. í•™ìŠµ ë£¨í”„
    print("\nğŸš€ ë³¸ê²©ì ì¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        steps = 0
        
        for batch_x, batch_y in train_loader:
            batch_x, batch_y = batch_x.to(device), batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item() * batch_x.size(0)
            steps += batch_x.size(0)
            
        train_loss /= steps

        # 5. ê²€ì¦ ë£¨í”„
        model.eval()
        val_loss = 0.0
        correct_predictions = 0
        val_steps = 0
        
        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                outputs = model(batch_x)
                
                loss = criterion(outputs, batch_y)
                val_loss += loss.item() * batch_x.size(0)
                
                # ì˜ˆì¸¡ê°’ ë„ì¶œ (0.5 ì´ìƒì´ë©´ 1, ì•„ë‹ˆë©´ 0)
                predictions = (outputs > 0).float()
                correct_predictions += (predictions == batch_y).all(dim=1).sum().item()
                val_steps += batch_x.size(0)
                
        val_loss /= val_steps
        logical_error_rate = 1.0 - (correct_predictions / val_steps)

        print(f"[Epoch {epoch+1:02d}/{epochs}] "
              f"Train Loss: {train_loss:.4f} | "
              f"Val Loss: {val_loss:.4f} | "
              f"Val Logical Error Rate: {logical_error_rate * 100:.2f}%")

    # 6. ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥
    save_path = train_config.get('save_path', 'model_weights.pth')
    os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True) # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    torch.save(model.state_dict(), save_path)
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="configs/experiment_mlp.yaml", help="YAML ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()
    main(args.config)